{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level Up to Agentic AI: Roast My Resume Agent\n",
        "\n",
        "### IEEE IGDTUW Workshop — SOLUTIONS\n",
        "\n",
        "**This notebook has all TODO cells filled in.** Use it as a reference if you get stuck, or to catch up if you fall behind.\n",
        "\n",
        "**3 Levels:**\n",
        "- **Level 1** — Teach Your AI to Think (Structured Output)\n",
        "- **Level 2** — Give Your AI Superpowers (Tool Use)\n",
        "- **Level 3** — Make Your AI Argue With Itself (Self-Correction)\n",
        "\n",
        "**+ Bonus:** Deploy it as a web app, ATS scoring, LinkedIn post generator\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "**Before running this cell:**\n",
        "1. Go to <a href=\"https://console.groq.com/keys\" target=\"_blank\" rel=\"noopener noreferrer\">console.groq.com/keys</a>\n",
        "2. Create a new Groq API key\n",
        "3. Copy the key\n",
        "4. In Colab, click the **key icon** (Secrets) in the left sidebar\n",
        "5. Add a new secret: Name = `GROQ_API_KEY`, Value = your key\n",
        "6. Toggle the **notebook access** switch ON\n",
        "\n",
        "**Running locally?** Copy `.env.example` to `.env` and set your key there instead.\n",
        "\n",
        "Then run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SETUP — Run this cell first!\n",
        "# ============================================================\n",
        "!pip install -q -U groq python-dotenv\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "except Exception:\n",
        "    userdata = None\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def _get_groq_key():\n",
        "    key = os.getenv('GROQ_API_KEY')\n",
        "    if not key and userdata is not None:\n",
        "        try:\n",
        "            key = userdata.get('GROQ_API_KEY')\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not key:\n",
        "        raise ValueError('GROQ_API_KEY not found. Add it to Colab Secrets or .env.')\n",
        "    return key\n",
        "\n",
        "class _GroqResponse:\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "\n",
        "# ── Available Groq models (pick one) ──────────────────────────\n",
        "GROQ_MODELS = {\n",
        "    'llama-3.3-70b-versatile':  '70B params — best for structured JSON, strong instruction-following',\n",
        "    'qwen-3-32b':               '32B params — great reasoning, multilingual',\n",
        "    'openai/gpt-oss-20b':       '20B params — lightweight & fast',\n",
        "    'openai/gpt-oss-120b':      '120B params — most capable, may have lower free-tier limits',\n",
        "    'meta-llama/llama-4-scout-17b-16e-instruct': '17B MoE — newest Llama, tool-use capable',\n",
        "}\n",
        "\n",
        "class GroqModelAdapter:\n",
        "    def __init__(self, model_name='llama-3.3-70b-versatile'):\n",
        "        self.client = Groq(api_key=_get_groq_key())\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def generate_content(self, prompt):\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[{'role': 'user', 'content': prompt}],\n",
        "            temperature=0.3,\n",
        "        )\n",
        "        text = (completion.choices[0].message.content or '').strip()\n",
        "        return _GroqResponse(text)\n",
        "\n",
        "# Configure the API\n",
        "# ── Choose your model (change here to try a different one) ────\n",
        "SELECTED_MODEL = os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile')\n",
        "model = GroqModelAdapter(SELECTED_MODEL)\n",
        "print(f\"Using model: {SELECTED_MODEL}\")\n",
        "print(f\"Available models: {', '.join(GROQ_MODELS.keys())}\\n\")\n",
        "\n",
        "# Quick test — if this prints a response, you're good!\n",
        "test = model.generate_content(\"Say 'Setup complete!' and nothing else.\")\n",
        "print(f\"[OK] {test.text.strip()}\")\n",
        "print(\"\\nYou're ready to build your agent.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check rate limit / quota (optional)\n",
        "\n",
        "Groq lets you monitor usage from the console. You can:\n",
        "- **Dashboard:** Open <a href=\"https://console.groq.com\" target=\"_blank\" rel=\"noopener noreferrer\">console.groq.com</a> (same account as your API key) to see RPM/TPM/RPD usage.\n",
        "- **Probe:** Run the next cell to make one test request — if it succeeds, you have quota; if 429, it will show \"retry in Xs\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CHECK QUOTA / RATE LIMIT (run in Colab)\n",
        "# ============================================================\n",
        "# Official dashboard (open in browser — same Groq account as API key):\n",
        "print(\"Rate limit dashboard: https://console.groq.com\")\n",
        "print(\"Or: https://console.groq.com\\n\")\n",
        "\n",
        "# Probe: one request to see if you have quota right now\n",
        "import re\n",
        "try:\n",
        "    r = model.generate_content(\"Reply with one word: OK\")\n",
        "    print(\"[OK] You have quota. Response:\", r.text.strip()[:50])\n",
        "except Exception as e:\n",
        "    err = str(e)\n",
        "    print(\"[429 / quota] Request failed.\")\n",
        "    if \"retry in\" in err.lower():\n",
        "        sec = re.search(r\"retry in (\\d+\\.?\\d*)s\", err, re.I)\n",
        "        if sec:\n",
        "            print(f\"  → Wait {float(sec.group(1)):.0f}s and try again.\")\n",
        "    if \"limit: 0\" in err:\n",
        "        print(\"  → Check your Groq usage in the console and verify GROQ_API_KEY in Secrets/.env.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sample Resume Bullets\n",
        "\n",
        "Pick one to roast (or use your own!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SAMPLE RESUME BULLETS — Pick one or write your own!\n",
        "# ============================================================\n",
        "\n",
        "samples = [\n",
        "    \"Proficient in MS Office and team management\",\n",
        "    \"Worked on various projects using Python\",\n",
        "    \"Good communication skills\",\n",
        "    \"Responsible for handling database operations\",\n",
        "    \"Participated in college hackathon and won prize\",\n",
        "    \"Familiar with machine learning concepts\",\n",
        "    \"Did internship at a startup and learned many things\",\n",
        "    \"Team player with leadership qualities\",\n",
        "]\n",
        "\n",
        "# === PICK YOUR BULLET ===\n",
        "resume_bullet = samples[0]\n",
        "\n",
        "print(f\"[NOTE] Your bullet: \\\"{resume_bullet}\\\"\")\n",
        "print(\"\\nLet's roast it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## LEVEL 1: Teach Your AI to Think\n",
        "\n",
        "Most people use LLMs like this: *\"Write me something\"* → get a wall of text.\n",
        "\n",
        "Agents think differently: *\"Return structured data\"* → get JSON you can actually use in code.\n",
        "\n",
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 1: Structured Roast — SOLUTION\n",
        "# ============================================================\n",
        "\n",
        "prompt = f\"\"\"You are a brutally honest resume reviewer. You're funny but constructive.\n",
        "Analyze this resume bullet point and return ONLY valid JSON — no markdown, no explanation.\n",
        "\n",
        "Resume bullet: \"{resume_bullet}\"\n",
        "\n",
        "Return JSON with these exact keys:\n",
        "- \"score\": integer from 1 to 10 (10 = perfect, 1 = delete immediately)\n",
        "- \"roast\": a funny but honest critique in 2-3 sentences (be savage but helpful)\n",
        "- \"rewrite\": an improved version of the bullet point (start with an action verb, include metrics if possible)\n",
        "- \"keywords_missing\": a list of 3-5 strong keywords that should be added to make this bullet stand out\n",
        "\"\"\"\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response = model.generate_content(prompt)\n",
        "text = response.text.strip()\n",
        "if text.startswith('```'):\n",
        "    text = text.split('\\n', 1)[1]\n",
        "if text.endswith('```'):\n",
        "    text = text.rsplit('```', 1)[0]\n",
        "\n",
        "result_1 = json.loads(text.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(f\"[TARGET] Score: {result_1['score']}/10\")\n",
        "print(f\"\\n[FIRE] Roast: {result_1['roast']}\")\n",
        "print(f\"\\n[SPARKLE] Rewrite: {result_1['rewrite']}\")\n",
        "print(f\"\\n[KEY] Missing Keywords: {', '.join(result_1['keywords_missing'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Agentic Pattern #1: Structured Output** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LEVEL 2: Give Your AI Superpowers\n",
        "\n",
        "### The Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# THE TOOL — Pre-built (just run this cell)\n",
        "# ============================================================\n",
        "\n",
        "def get_role_requirements(role: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns what recruiters look for in a specific role.\n",
        "    This is your agent's 'superpower' — external knowledge\n",
        "    that the LLM doesn't have on its own.\n",
        "    \"\"\"\n",
        "    requirements = {\n",
        "        \"software engineer\": (\n",
        "            \"Strong DSA fundamentals, system design, clean code practices, \"\n",
        "            \"CI/CD experience, testing frameworks, specific language/framework \"\n",
        "            \"expertise (not just 'Python'), quantified impact metrics (%, $, users), \"\n",
        "            \"open source contributions\"\n",
        "        ),\n",
        "        \"data scientist\": (\n",
        "            \"Statistical modeling, Python/R proficiency, SQL mastery, \"\n",
        "            \"ML frameworks (scikit-learn, PyTorch), A/B testing design, \"\n",
        "            \"business impact quantification, data pipeline experience, \"\n",
        "            \"visualization skills\"\n",
        "        ),\n",
        "        \"product manager\": (\n",
        "            \"User research methodology, metrics-driven decisions (DAU, retention, conversion), \"\n",
        "            \"roadmap planning, stakeholder management, market analysis, A/B testing, PRD writing\"\n",
        "        ),\n",
        "        \"ml engineer\": (\n",
        "            \"Model training and fine-tuning, MLOps (MLflow, Kubeflow), \"\n",
        "            \"distributed training, model serving (TensorRT, ONNX), \"\n",
        "            \"data pipeline engineering, experiment tracking, production deployment\"\n",
        "        ),\n",
        "        \"frontend developer\": (\n",
        "            \"React/Vue/Angular expertise, performance optimization (Core Web Vitals), \"\n",
        "            \"accessibility (WCAG), responsive design, state management, \"\n",
        "            \"testing (Jest, Cypress), design system experience\"\n",
        "        ),\n",
        "        \"backend developer\": (\n",
        "            \"API design (REST/GraphQL), database optimization (SQL + NoSQL), \"\n",
        "            \"caching strategies, message queues, microservices architecture, \"\n",
        "            \"monitoring/observability, load testing\"\n",
        "        ),\n",
        "        \"devops engineer\": (\n",
        "            \"CI/CD pipeline design, IaC (Terraform, Pulumi), container orchestration (K8s), \"\n",
        "            \"monitoring (Prometheus, Grafana), cloud platforms (AWS/GCP/Azure), \"\n",
        "            \"security best practices, incident response\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    role_lower = role.lower()\n",
        "    for key, value in requirements.items():\n",
        "        if key in role_lower:\n",
        "            return value\n",
        "    return (\n",
        "        \"Quantified achievements, specific technologies, measurable impact, \"\n",
        "        \"action verbs, industry-specific keywords, problem-solving examples\"\n",
        "    )\n",
        "\n",
        "# --- Test the tool ---\n",
        "target_role = \"Software Engineer\"\n",
        "context = get_role_requirements(target_role)\n",
        "\n",
        "print(f\"[TOOL] Tool called: get_role_requirements('{target_role}')\")\n",
        "print(f\"\\n[BRIEFCASE] Recruiters look for: {context}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 2: Tool-Powered Roast — SOLUTION\n",
        "# ============================================================\n",
        "\n",
        "prompt_2 = f\"\"\"You are a resume expert who knows exactly what recruiters want.\n",
        "\n",
        "For a {target_role} role, recruiters specifically look for:\n",
        "{context}\n",
        "\n",
        "Analyze this resume bullet point with that context in mind:\n",
        "\"{resume_bullet}\"\n",
        "\n",
        "Return ONLY valid JSON — no markdown, no explanation — with these exact keys:\n",
        "- \"score\": integer 1-10 (how well does this bullet match what recruiters want?)\n",
        "- \"roast\": brutal but constructive critique that references specific recruiter expectations (2-3 sentences)\n",
        "- \"rewrite\": rewritten bullet optimized for {target_role} applications (start with action verb, include metrics)\n",
        "- \"missing_for_role\": a string describing what key skills/keywords are missing based on the recruiter expectations\n",
        "\"\"\"\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response_2 = model.generate_content(prompt_2)\n",
        "text_2 = response_2.text.strip()\n",
        "if text_2.startswith('```'):\n",
        "    text_2 = text_2.split('\\n', 1)[1]\n",
        "if text_2.endswith('```'):\n",
        "    text_2 = text_2.rsplit('```', 1)[0]\n",
        "\n",
        "result_2 = json.loads(text_2.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(f\"[TARGET] Score: {result_2['score']}/10\")\n",
        "print(f\"\\n[FIRE] Roast: {result_2['roast']}\")\n",
        "print(f\"\\n[SPARKLE] Rewrite: {result_2['rewrite']}\")\n",
        "print(f\"\\n[BRIEFCASE] Missing for {target_role}: {result_2['missing_for_role']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Agentic Pattern #2: Tool Use** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LEVEL 3: Make Your AI Argue With Itself\n",
        "\n",
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 3: The Self-Critique Loop — SOLUTION\n",
        "# ============================================================\n",
        "\n",
        "rewrite_from_level_2 = result_2['rewrite']\n",
        "\n",
        "prompt_3 = f\"\"\"You are a senior hiring manager at a FAANG company (Google, Meta, Amazon, etc.).\n",
        "You have reviewed thousands of resumes and know exactly what stands out.\n",
        "\n",
        "A junior resume writer produced this bullet point for a {target_role} resume:\n",
        "\"{rewrite_from_level_2}\"\n",
        "\n",
        "For context, recruiters for {target_role} roles look for:\n",
        "{context}\n",
        "\n",
        "Your job:\n",
        "1. Find EXACTLY 3 specific problems with this rewrite (be precise, not vague)\n",
        "2. Fix all 3 problems and produce the FINAL, perfected version\n",
        "3. Rate your confidence that this final version would pass ATS and impress a recruiter\n",
        "\n",
        "Return ONLY valid JSON — no markdown, no explanation — with:\n",
        "- \"problems\": a list of exactly 3 strings, each describing a specific issue\n",
        "- \"final_version\": the ultimate perfected bullet point\n",
        "- \"confidence_score\": integer 1-10 (10 = guaranteed interview callback)\n",
        "\"\"\"\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response_3 = model.generate_content(prompt_3)\n",
        "text_3 = response_3.text.strip()\n",
        "if text_3.startswith('```'):\n",
        "    text_3 = text_3.split('\\n', 1)[1]\n",
        "if text_3.endswith('```'):\n",
        "    text_3 = text_3.rsplit('```', 1)[0]\n",
        "\n",
        "result_3 = json.loads(text_3.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(\"[THINKING] Self-Critique Results:\")\n",
        "print(\"\\nProblems found:\")\n",
        "for i, problem in enumerate(result_3['problems'], 1):\n",
        "    print(f\"  {i}. {problem}\")\n",
        "\n",
        "print(f\"\\n[OK] Final Version: {result_3['final_version']}\")\n",
        "print(f\"\\n[STATS] Confidence: {result_3['confidence_score']}/10\")\n",
        "\n",
        "# === THE BEFORE / AFTER ===\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"[NOTE] BEFORE vs AFTER\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[X] Before: \\\"{resume_bullet}\\\"\")\n",
        "print(f\"\\n[OK] After:  \\\"{result_3['final_version']}\\\"\")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Agentic Pattern #3: Self-Correction** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def stage_print(stage, icon, color, message):\n",
        "    \"\"\"Print a visually distinct stage header.\"\"\"\n",
        "    colors = {\n",
        "        'cyan': '\\033[96m',\n",
        "        'red': '\\033[91m',\n",
        "        'green': '\\033[92m',\n",
        "        'yellow': '\\033[93m',\n",
        "        'magenta': '\\033[95m',\n",
        "        'white': '\\033[97m',\n",
        "        'reset': '\\033[0m'\n",
        "    }\n",
        "    c = colors.get(color, colors['white'])\n",
        "    r = colors['reset']\n",
        "    print(f\"\\n{c}{'='*60}{r}\")\n",
        "    try:\n",
        "        # Try printing with icon\n",
        "        print(f\"{c}{icon}  [ {stage} ]{r}\")\n",
        "    except UnicodeEncodeError:\n",
        "        # Fallback if terminal doesn't support emoji\n",
        "        print(f\"{c}[ {stage} ]{r}\")\n",
        "    print(f\"{c}{'='*60}{r}\")\n",
        "    time.sleep(0.5)\n",
        "    print(f\"\\n{message}\\n\")\n",
        "\n",
        "\n",
        "def thinking_dots(text, duration=1.5):\n",
        "    \"\"\"Simulate agent thinking.\"\"\"\n",
        "    import sys\n",
        "    sys.stdout.write(f\"\\033[90m{text}\")\n",
        "    for _ in range(3):\n",
        "        time.sleep(duration / 3)\n",
        "        sys.stdout.write(\".\")\n",
        "        sys.stdout.flush()\n",
        "    print(\"\\033[0m\")\n",
        "\n",
        "\n",
        "def get_role_requirements(role: str) -> str:\n",
        "    \"\"\"TOOL: Returns what recruiters look for in a specific role.\"\"\"\n",
        "    requirements = {\n",
        "        \"software engineer\": \"Strong DSA fundamentals, system design, clean code practices, CI/CD experience, testing frameworks, specific language/framework expertise (not just 'Python'), quantified impact metrics (%, $, users), open source contributions\",\n",
        "        \"data scientist\": \"Statistical modeling, Python/R proficiency, SQL mastery, ML frameworks (scikit-learn, PyTorch), A/B testing design, business impact quantification, data pipeline experience, visualization skills\",\n",
        "        \"product manager\": \"User research methodology, metrics-driven decisions (DAU, retention, conversion), roadmap planning, stakeholder management, market analysis, A/B testing, PRD writing\",\n",
        "        \"ml engineer\": \"Model training and fine-tuning, MLOps (MLflow, Kubeflow), distributed training, model serving (TensorRT, ONNX), data pipeline engineering, experiment tracking, production deployment\",\n",
        "        \"frontend developer\": \"React/Vue/Angular expertise, performance optimization (Core Web Vitals), accessibility (WCAG), responsive design, state management, testing (Jest, Cypress), design system experience\",\n",
        "        \"backend developer\": \"API design (REST/GraphQL), database optimization (SQL + NoSQL), caching strategies, message queues, microservices architecture, monitoring/observability, load testing\",\n",
        "        \"devops engineer\": \"CI/CD pipeline design, IaC (Terraform, Pulumi), container orchestration (K8s), monitoring (Prometheus, Grafana), cloud platforms (AWS/GCP/Azure), security best practices, incident response\"\n",
        "    }\n",
        "    role_lower = role.lower()\n",
        "    for key, value in requirements.items():\n",
        "        if key in role_lower:\n",
        "            return value\n",
        "    return \"Quantified achievements, specific technologies, measurable impact, action verbs, industry-specific keywords, problem-solving examples\"\n",
        "\n",
        "\n",
        "def call_llm(prompt, retries=4, delay=10):\n",
        "    \"\"\"Call Groq and return parsed JSON with retry logic and rate-limit backoff.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            text = response.text.strip()\n",
        "            if text.startswith('```'):\n",
        "                text = text.split('\\n', 1)[1]\n",
        "            if text.endswith('```'):\n",
        "                text = text.rsplit('```', 1)[0]\n",
        "            return json.loads(text.strip())\n",
        "        except Exception as e:\n",
        "            err_str = str(e).lower()\n",
        "            is_rate_limit = \"429\" in str(e) or \"resource exhausted\" in err_str or \"quota\" in err_str\n",
        "            if is_rate_limit and attempt < retries - 1:\n",
        "                print(f\"\\n\\033[93mRate limit hit. Retrying in {delay}s... (attempt {attempt+1}/{retries})\\033[0m\")\n",
        "                time.sleep(delay)\n",
        "                delay = min(delay * 2, 65)  # Exponential backoff, cap at 65s\n",
        "            else:\n",
        "                if is_rate_limit:\n",
        "                    print(\"\\033[91mQuota exceeded. Try a different model from GROQ_MODELS in Setup, or verify GROQ_API_KEY.\\033[0m\")\n",
        "                raise e\n",
        "\n",
        "\n",
        "def roast_my_resume(bullet: str, role: str) -> dict:\n",
        "    \"\"\"Run the full Level 1 → 2 → 3 pipeline for a single bullet and role. Used by Gradio.\"\"\"\n",
        "    context = get_role_requirements(role)\n",
        "    # Level 1: structured roast\n",
        "    p1 = f\"\"\"You are a brutally honest resume reviewer. You're funny but constructive.\n",
        "Analyze this resume bullet point and return ONLY valid JSON — no markdown, no explanation.\n",
        "\n",
        "Resume bullet: \"{bullet}\"\n",
        "\n",
        "Return JSON with these exact keys:\n",
        "- \\\"score\\\": integer from 1 to 10 (10 = perfect, 1 = delete immediately)\n",
        "- \\\"roast\\\": a funny but honest critique in 2-3 sentences (be savage but helpful)\n",
        "- \\\"rewrite\\\": an improved version of the bullet point (start with an action verb, include metrics if possible)\n",
        "- \\\"keywords_missing\\\": a list of 3-5 strong keywords that should be added to make this bullet stand out\n",
        "\"\"\"\n",
        "    analysis = call_llm(p1)\n",
        "    # Level 2: tool-powered rewrite\n",
        "    p2 = f\"\"\"You are a resume expert who knows exactly what recruiters want.\n",
        "\n",
        "For a {role} role, recruiters specifically look for:\n",
        "{context}\n",
        "\n",
        "Analyze this resume bullet point with that context in mind:\n",
        "\"{bullet}\"\n",
        "\n",
        "Return ONLY valid JSON — no markdown, no explanation — with these exact keys:\n",
        "- \\\"score\\\": integer 1-10 (how well does this bullet match what recruiters want?)\n",
        "- \\\"roast\\\": brutal but constructive critique that references specific recruiter expectations (2-3 sentences)\n",
        "- \\\"rewrite\\\": rewritten bullet optimized for {role} applications (start with action verb, include metrics)\n",
        "- \\\"missing_for_role\\\": a string describing what key skills/keywords are missing based on the recruiter expectations\n",
        "\"\"\"\n",
        "    result_2 = call_llm(p2)\n",
        "    # Level 3: self-critique\n",
        "    rewrite = result_2['rewrite']\n",
        "    p3 = f\"\"\"You are a senior hiring manager at a FAANG company (Google, Meta, Amazon, etc.).\n",
        "You have reviewed thousands of resumes and know exactly what stands out.\n",
        "\n",
        "A junior resume writer produced this bullet point for a {role} resume:\n",
        "\"{rewrite}\"\n",
        "\n",
        "For context, recruiters for {role} roles look for:\n",
        "{context}\n",
        "\n",
        "Your job:\n",
        "1. Find EXACTLY 3 specific problems with this rewrite (be precise, not vague)\n",
        "2. Fix all 3 problems and produce the FINAL, perfected version\n",
        "3. Rate your confidence that this final version would pass ATS and impress a recruiter\n",
        "\n",
        "Return ONLY valid JSON — no markdown, no explanation — with:\n",
        "- \\\"problems\\\": a list of exactly 3 strings, each describing a specific issue\n",
        "- \\\"final_version\\\": the ultimate perfected bullet point\n",
        "- \\\"confidence_score\\\": integer 1-10 (10 = guaranteed interview callback)\n",
        "\"\"\"\n",
        "    result_3 = call_llm(p3)\n",
        "    return {\n",
        "        'original': bullet,\n",
        "        'initial_score': analysis['score'],\n",
        "        'roast': analysis['roast'],\n",
        "        'problems_found': result_3['problems'],\n",
        "        'final_version': result_3['final_version'],\n",
        "        'confidence': result_3['confidence_score'],\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"[OK] Helpers loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# BONUS LEVELS\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BONUS: ATS Score Gamification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ATS SCORE — Before vs After\n",
        "# ============================================================\n",
        "\n",
        "original_bullet = resume_bullet\n",
        "final_bullet = result_3['final_version']\n",
        "\n",
        "ats_prompt = f\"\"\"You are an Applicant Tracking System (ATS) scanner.\n",
        "Score these two resume bullets for ATS compatibility for a {target_role} role.\n",
        "\n",
        "Key factors: action verbs, quantified metrics, relevant keywords,\n",
        "specificity, industry standard terminology.\n",
        "\n",
        "Recruiters for {target_role} look for: {context}\n",
        "\n",
        "Bullet A (original): \"{original_bullet}\"\n",
        "Bullet B (improved): \"{final_bullet}\"\n",
        "\n",
        "Return ONLY valid JSON with:\n",
        "- \"original_ats_score\": integer 1-100\n",
        "- \"final_ats_score\": integer 1-100\n",
        "- \"improvement\": percentage improvement as a string (e.g., \"+65%\")\n",
        "- \"ats_tips\": list of 3 tips for even higher ATS compatibility\n",
        "\"\"\"\n",
        "\n",
        "response_ats = model.generate_content(ats_prompt)\n",
        "text_ats = response_ats.text.strip()\n",
        "if text_ats.startswith('```'):\n",
        "    text_ats = text_ats.split('\\n', 1)[1]\n",
        "if text_ats.endswith('```'):\n",
        "    text_ats = text_ats.rsplit('```', 1)[0]\n",
        "ats_result = json.loads(text_ats.strip())\n",
        "\n",
        "# Display\n",
        "print(\"[ROBOT] ATS COMPATIBILITY SCAN\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"\\n[X] Original: {ats_result['original_ats_score']}/100\")\n",
        "bar_orig = \"\\u2588\" * (ats_result['original_ats_score'] // 5) + \"\\u2591\" * (20 - ats_result['original_ats_score'] // 5)\n",
        "print(f\"   [{bar_orig}]\")\n",
        "\n",
        "print(f\"\\n[OK] Final:    {ats_result['final_ats_score']}/100\")\n",
        "bar_final = \"\\u2588\" * (ats_result['final_ats_score'] // 5) + \"\\u2591\" * (20 - ats_result['final_ats_score'] // 5)\n",
        "print(f\"   [{bar_final}]\")\n",
        "\n",
        "print(f\"\\n[CHART] Improvement: {ats_result['improvement']}\")\n",
        "print(f\"\\n[TIP] Tips for even higher scores:\")\n",
        "for tip in ats_result['ats_tips']:\n",
        "    print(f\"   \\u2022 {tip}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## SECRET LEVEL 4: Deploy as a Web App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SECRET LEVEL 4: Deploy with Gradio\n",
        "# ============================================================\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def roast_app(bullet: str, role: str) -> str:\n",
        "    \"\"\"Wrapper for the Gradio interface.\"\"\"\n",
        "    try:\n",
        "        result = roast_my_resume(bullet, role)\n",
        "        output = f\"\"\"## Results\\n\n",
        "**Original:** \\\"{result['original']}\\\"\\n\n",
        "**Initial Score:** {result['initial_score']}/10\\n\n",
        "**Roast:** {result['roast']}\\n\n",
        "---\\n\n",
        "**Problems Found:**\\n\"\"\"\n",
        "        for i, p in enumerate(result['problems_found'], 1):\n",
        "            output += f\"{i}. {p}\\n\"\n",
        "        output += f\"\"\"\\n---\\n\n",
        "**Final Version:** \\\"{result['final_version']}\\\"\\n\n",
        "**Confidence:** {result['confidence']}/10\n",
        "\"\"\"\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}. Try again!\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=roast_app,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Resume Bullet\", placeholder=\"Paste your resume bullet here...\"),\n",
        "        gr.Dropdown(\n",
        "            label=\"Target Role\",\n",
        "            choices=[\"Software Engineer\", \"Data Scientist\", \"Product Manager\",\n",
        "                     \"ML Engineer\", \"Frontend Developer\", \"Backend Developer\",\n",
        "                     \"DevOps Engineer\"],\n",
        "            value=\"Software Engineer\"\n",
        "        ),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Agent Output\"),\n",
        "    title=\"[FIRE] Roast My Resume Agent\",\n",
        "    description=\"An AI agent that roasts your resume, rewrites it, and argues with itself to make it perfect.\",\n",
        "    examples=[\n",
        "        [\"Proficient in MS Office and team management\", \"Software Engineer\"],\n",
        "        [\"Familiar with machine learning concepts\", \"ML Engineer\"],\n",
        "        [\"Good communication skills\", \"Product Manager\"],\n",
        "    ],\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## BONUS: LinkedIn Post Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LINKEDIN POST GENERATOR\n",
        "# ============================================================\n",
        "\n",
        "linkedin_prompt = \"\"\"You are a LinkedIn post writer for a college student who just\n",
        "built their first AI agent at a workshop.\n",
        "\n",
        "Write a professional but enthusiastic LinkedIn post (150-200 words) about:\n",
        "- They attended the \"Level Up to Agentic AI\" workshop by IEEE IGDTUW\n",
        "- Mentored by Ishan (AI Engineer, GDG Cloud New Delhi speaker)\n",
        "- They built a \"Roast My Resume\" AI Agent from scratch in Python\n",
        "- The agent uses 3 agentic patterns: Structured Output, Tool Calling, Self-Correction\n",
        "- They deployed it as a live web app using Gradio\n",
        "- They're excited about AI Engineering and Agentic AI\n",
        "\n",
        "Make it sound genuine, not salesy. Include 3-4 relevant hashtags.\n",
        "Don't use excessive emojis — keep it professional.\n",
        "\n",
        "Return ONLY valid JSON with:\n",
        "- \"post\": the full LinkedIn post text\n",
        "- \"hashtags\": list of hashtags used\n",
        "\"\"\"\n",
        "\n",
        "response_li = model.generate_content(linkedin_prompt)\n",
        "text_li = response_li.text.strip()\n",
        "if text_li.startswith('```'):\n",
        "    text_li = text_li.split('\\n', 1)[1]\n",
        "if text_li.endswith('```'):\n",
        "    text_li = text_li.rsplit('```', 1)[0]\n",
        "li_result = json.loads(text_li.strip())\n",
        "\n",
        "print(\"[NOTE] Your LinkedIn Post (copy-paste ready):\\n\")\n",
        "print(\"=\" * 50)\n",
        "print(li_result['post'])\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n[CLIP] Just copy the text above and paste it into LinkedIn!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## What You Built Today\n",
        "\n",
        "| Pattern | What It Does | Where It's Used in Production |\n",
        "|---------|-------------|------------------------------|\n",
        "| **Structured Output** | LLM returns JSON, not prose | Every AI agent ever |\n",
        "| **Tool Use** | Agent calls functions for external data | Google Search, API calls, DB queries |\n",
        "| **Self-Correction** | Agent critiques and fixes its own output | Devin, AutoGPT, production pipelines |\n",
        "\n",
        "### Where to Go Next\n",
        "\n",
        "- **LangGraph** — Build multi-agent systems with complex orchestration\n",
        "- **MCP (Model Context Protocol)** — Universal standard for agent tools\n",
        "- **Vertex AI / Cloud Run** — Deploy agents to production 24/7\n",
        "- **Groq Console** — Your API key is free. Keep building.\n",
        "\n",
        "### You just built what companies pay ₹20L+ for. Keep building.\n",
        "\n",
        "---\n",
        "\n",
        "*Workshop by Ishan — AI Engineer | GDG Cloud New Delhi*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}