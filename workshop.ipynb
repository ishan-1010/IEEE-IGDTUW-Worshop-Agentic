{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Level Up to Agentic AI: Roast My Resume Agent\n",
        "\n",
        "### IEEE IGDTUW Workshop\n",
        "\n",
        "**What you'll build:** An AI agent that reads your resume bullet points, roasts the weak ones, rewrites them stronger, and then *critiques its own rewrite* to make them perfect.\n",
        "\n",
        "**3 Levels:**\n",
        "- **Level 1** — Teach Your AI to Think (Structured Output)\n",
        "- **Level 2** — Give Your AI Superpowers (Tool Use)\n",
        "- **Level 3** — Make Your AI Argue With Itself (Self-Correction)\n",
        "\n",
        "**+ Bonus:** Deploy it as a web app, ATS scoring, LinkedIn post generator\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "**Before running this cell:**\n",
        "1. Go to [aistudio.google.com](https://aistudio.google.com)\n",
        "2. Click **\"Get API Key\"** → **\"Create API key in new project\"**\n",
        "3. Copy the key\n",
        "4. In Colab, click the **key icon** (Secrets) in the left sidebar\n",
        "5. Add a new secret: Name = `GEMINI_API_KEY`, Value = your key\n",
        "6. Toggle the **notebook access** switch ON\n",
        "\n",
        "Then run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SETUP — Run this cell first!\n",
        "# ============================================================\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "# Configure the API\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "# Use gemini-2.5-flash (reliable free tier; 2.0-flash and 2.5-pro often have limit: 0 on new keys).\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Quick test — if this prints a response, you're good!\n",
        "test = model.generate_content(\"Say 'Setup complete!' and nothing else.\")\n",
        "print(f\"[OK] {test.text.strip()}\")\n",
        "print(\"\\nYou're ready to build your agent.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check rate limit / quota (optional)\n",
        "\n",
        "Google doesn't expose \"remaining requests\" via API. You can:\n",
        "- **Dashboard:** Open the link below (same Google account as your API key) to see RPM/TPM/RPD usage.\n",
        "- **Probe:** Run the next cell to make one test request — if it succeeds, you have quota; if 429, it will show \"retry in Xs\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CHECK QUOTA / RATE LIMIT (run in Colab)\n",
        "# ============================================================\n",
        "# Official dashboard (open in browser — same Google account as API key):\n",
        "print(\"Rate limit dashboard: https://ai.dev/rate-limit\")\n",
        "print(\"Or: https://aistudio.google.com/usage?tab=rate-limit\\n\")\n",
        "\n",
        "# Probe: one request to see if you have quota right now\n",
        "import re\n",
        "try:\n",
        "    r = model.generate_content(\"Reply with one word: OK\")\n",
        "    print(\"[OK] You have quota. Response:\", r.text.strip()[:50])\n",
        "except Exception as e:\n",
        "    err = str(e)\n",
        "    print(\"[429 / quota] Request failed.\")\n",
        "    if \"retry in\" in err.lower():\n",
        "        sec = re.search(r\"retry in (\\d+\\.?\\d*)s\", err, re.I)\n",
        "        if sec:\n",
        "            print(f\"  → Wait {float(sec.group(1)):.0f}s and try again.\")\n",
        "    if \"limit: 0\" in err:\n",
        "        print(\"  → Project has 0 quota. See README: create key from aistudio.google.com, enable API, or try another account.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Sample Resume Bullets\n",
        "\n",
        "Pick one to roast (or use your own!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SAMPLE RESUME BULLETS — Pick one or write your own!\n",
        "# ============================================================\n",
        "\n",
        "samples = [\n",
        "    \"Proficient in MS Office and team management\",\n",
        "    \"Worked on various projects using Python\",\n",
        "    \"Good communication skills\",\n",
        "    \"Responsible for handling database operations\",\n",
        "    \"Participated in college hackathon and won prize\",\n",
        "    \"Familiar with machine learning concepts\",\n",
        "    \"Did internship at a startup and learned many things\",\n",
        "    \"Team player with leadership qualities\",\n",
        "]\n",
        "\n",
        "# === PICK YOUR BULLET ===\n",
        "# Change the index or write your own string:\n",
        "resume_bullet = samples[0]\n",
        "\n",
        "print(f\"[NOTE] Your bullet: \\\"{resume_bullet}\\\"\")\n",
        "print(\"\\nLet's roast it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## LEVEL 1: Teach Your AI to Think\n",
        "\n",
        "Most people use LLMs like this: *\"Write me something\"* → get a wall of text.\n",
        "\n",
        "Agents think differently: *\"Return structured data\"* → get JSON you can actually use in code.\n",
        "\n",
        "### Your Task\n",
        "\n",
        "Write a prompt that tells Gemini to analyze the resume bullet and return **JSON** with these fields:\n",
        "- `score` — a rating from 1 to 10\n",
        "- `roast` — a funny but honest critique (2-3 sentences)\n",
        "- `rewrite` — an improved version of the bullet\n",
        "- `keywords_missing` — a list of strong keywords that should be added\n",
        "\n",
        "**Hints:**\n",
        "- Tell the model to return \"ONLY valid JSON\"\n",
        "- Describe the persona (e.g., \"brutally honest resume reviewer\")\n",
        "- Include the resume bullet in the prompt using the variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 1: Structured Roast\n",
        "# ============================================================\n",
        "\n",
        "# ======================= YOUR CODE ==========================\n",
        "# TODO: Write your prompt below.\n",
        "# The prompt should tell Gemini to:\n",
        "#   1. Act as a brutally honest resume reviewer\n",
        "#   2. Analyze the resume_bullet variable\n",
        "#   3. Return ONLY valid JSON with: score, roast, rewrite, keywords_missing\n",
        "#\n",
        "# Example structure (fill in the actual prompt):\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "YOUR PROMPT HERE\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ===================== END YOUR CODE ========================\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response = model.generate_content(prompt)\n",
        "text = response.text.strip()\n",
        "# Clean up markdown code fences if the model adds them\n",
        "if text.startswith('```'):\n",
        "    text = text.split('\\n', 1)[1]\n",
        "if text.endswith('```'):\n",
        "    text = text.rsplit('```', 1)[0]\n",
        "\n",
        "result_1 = json.loads(text.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(f\"[TARGET] Score: {result_1['score']}/10\")\n",
        "print(f\"\\n[FIRE] Roast: {result_1['roast']}\")\n",
        "print(f\"\\n[SPARKLE] Rewrite: {result_1['rewrite']}\")\n",
        "print(f\"\\n[KEY] Missing Keywords: {', '.join(result_1['keywords_missing'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What just happened?\n",
        "\n",
        "You told the LLM to return **structured data** instead of paragraphs. This is the foundation of every AI agent:\n",
        "- The output is *parseable* — your code can read and use each field\n",
        "- The output is *consistent* — same fields every time\n",
        "- The output is *pipeable* — you can feed it into the next step automatically\n",
        "\n",
        "**Agentic Pattern #1: Structured Output** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LEVEL 2: Give Your AI Superpowers\n",
        "\n",
        "Right now, the agent is guessing what a \"good\" resume looks like. But what if it *knew* exactly what recruiters want for a specific role?\n",
        "\n",
        "That's what **tools** do. A tool is just a Python function the agent can use to get information it doesn't have.\n",
        "\n",
        "### The Tool\n",
        "\n",
        "Run the cell below — it defines a function that returns what recruiters actually look for:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# THE TOOL — Pre-built for you (just run this cell)\n",
        "# ============================================================\n",
        "\n",
        "def get_role_requirements(role: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns what recruiters look for in a specific role.\n",
        "    This is your agent's 'superpower' — external knowledge\n",
        "    that the LLM doesn't have on its own.\n",
        "    \"\"\"\n",
        "    requirements = {\n",
        "        \"software engineer\": (\n",
        "            \"Strong DSA fundamentals, system design, clean code practices, \"\n",
        "            \"CI/CD experience, testing frameworks, specific language/framework \"\n",
        "            \"expertise (not just 'Python'), quantified impact metrics (%, $, users), \"\n",
        "            \"open source contributions\"\n",
        "        ),\n",
        "        \"data scientist\": (\n",
        "            \"Statistical modeling, Python/R proficiency, SQL mastery, \"\n",
        "            \"ML frameworks (scikit-learn, PyTorch), A/B testing design, \"\n",
        "            \"business impact quantification, data pipeline experience, \"\n",
        "            \"visualization skills\"\n",
        "        ),\n",
        "        \"product manager\": (\n",
        "            \"User research methodology, metrics-driven decisions (DAU, retention, conversion), \"\n",
        "            \"roadmap planning, stakeholder management, market analysis, A/B testing, PRD writing\"\n",
        "        ),\n",
        "        \"ml engineer\": (\n",
        "            \"Model training and fine-tuning, MLOps (MLflow, Kubeflow), \"\n",
        "            \"distributed training, model serving (TensorRT, ONNX), \"\n",
        "            \"data pipeline engineering, experiment tracking, production deployment\"\n",
        "        ),\n",
        "        \"frontend developer\": (\n",
        "            \"React/Vue/Angular expertise, performance optimization (Core Web Vitals), \"\n",
        "            \"accessibility (WCAG), responsive design, state management, \"\n",
        "            \"testing (Jest, Cypress), design system experience\"\n",
        "        ),\n",
        "        \"backend developer\": (\n",
        "            \"API design (REST/GraphQL), database optimization (SQL + NoSQL), \"\n",
        "            \"caching strategies, message queues, microservices architecture, \"\n",
        "            \"monitoring/observability, load testing\"\n",
        "        ),\n",
        "        \"devops engineer\": (\n",
        "            \"CI/CD pipeline design, IaC (Terraform, Pulumi), container orchestration (K8s), \"\n",
        "            \"monitoring (Prometheus, Grafana), cloud platforms (AWS/GCP/Azure), \"\n",
        "            \"security best practices, incident response\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    role_lower = role.lower()\n",
        "    for key, value in requirements.items():\n",
        "        if key in role_lower:\n",
        "            return value\n",
        "    return (\n",
        "        \"Quantified achievements, specific technologies, measurable impact, \"\n",
        "        \"action verbs, industry-specific keywords, problem-solving examples\"\n",
        "    )\n",
        "\n",
        "# --- Test the tool ---\n",
        "target_role = \"Software Engineer\"  # Change this to any role!\n",
        "context = get_role_requirements(target_role)\n",
        "\n",
        "print(f\"[TOOL] Tool called: get_role_requirements('{target_role}')\")\n",
        "print(f\"\\n[BRIEFCASE] Recruiters look for: {context}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "Now write a prompt that **uses the tool's output** to make a smarter roast.\n",
        "\n",
        "The prompt should:\n",
        "1. Tell the agent it's a resume expert who *knows what recruiters want*\n",
        "2. Include the recruiter requirements from the tool (the `context` variable)\n",
        "3. Include the `target_role` so the agent tailors its advice\n",
        "4. Return JSON with: `score`, `roast`, `rewrite`, `missing_for_role`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 2: Tool-Powered Roast\n",
        "# ============================================================\n",
        "\n",
        "# ======================= YOUR CODE ==========================\n",
        "# TODO: Write your prompt below.\n",
        "# You have access to:\n",
        "#   - resume_bullet (the original bullet)\n",
        "#   - target_role (e.g., \"Software Engineer\")\n",
        "#   - context (what recruiters look for — from the tool)\n",
        "#\n",
        "# The prompt should use ALL THREE variables to make\n",
        "# a smarter, role-specific roast.\n",
        "#\n",
        "# Return JSON with: score, roast, rewrite, missing_for_role\n",
        "\n",
        "prompt_2 = f\"\"\"\n",
        "\n",
        "YOUR PROMPT HERE\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ===================== END YOUR CODE ========================\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response_2 = model.generate_content(prompt_2)\n",
        "text_2 = response_2.text.strip()\n",
        "if text_2.startswith('```'):\n",
        "    text_2 = text_2.split('\\n', 1)[1]\n",
        "if text_2.endswith('```'):\n",
        "    text_2 = text_2.rsplit('```', 1)[0]\n",
        "\n",
        "result_2 = json.loads(text_2.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(f\"[TARGET] Score: {result_2['score']}/10\")\n",
        "print(f\"\\n[FIRE] Roast: {result_2['roast']}\")\n",
        "print(f\"\\n[SPARKLE] Rewrite: {result_2['rewrite']}\")\n",
        "print(f\"\\n[BRIEFCASE] Missing for {target_role}: {result_2['missing_for_role']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What just happened?\n",
        "\n",
        "Your agent just used a **tool** — it called `get_role_requirements()` to get information it didn't have, then used that context to make a smarter decision.\n",
        "\n",
        "This is exactly how production agents work:\n",
        "- Agents call APIs, search databases, read files\n",
        "- The tool gives the agent **context** it can't get from its training data\n",
        "- The agent **decides** how to use that context\n",
        "\n",
        "**Agentic Pattern #2: Tool Use** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LEVEL 3: Make Your AI Argue With Itself\n",
        "\n",
        "The rewrite from Level 2 is good, but is it *perfect*? Probably not.\n",
        "\n",
        "The **Reflection Pattern** is the secret weapon of production AI agents. It works like this:\n",
        "\n",
        "1. Agent produces an output (the rewrite)\n",
        "2. A **second LLM call** critiques that output — \"Find 3 problems\"\n",
        "3. The agent fixes its own mistakes and produces a **final version**\n",
        "\n",
        "The agent is literally arguing with itself to get better.\n",
        "\n",
        "### Your Task\n",
        "\n",
        "Write a prompt that:\n",
        "1. Takes the rewrite from Level 2 (`result_2['rewrite']`)\n",
        "2. Acts as a **senior hiring manager** at a top company\n",
        "3. Finds **exactly 3 specific problems** with the rewrite\n",
        "4. Produces the **final, perfected version**\n",
        "5. Returns JSON with: `problems` (list of 3), `final_version`, `confidence_score` (1-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LEVEL 3: The Self-Critique Loop\n",
        "# ============================================================\n",
        "\n",
        "rewrite_from_level_2 = result_2['rewrite']\n",
        "\n",
        "# ======================= YOUR CODE ==========================\n",
        "# TODO: Write the critique prompt below.\n",
        "# You have access to:\n",
        "#   - rewrite_from_level_2 (the rewrite from Level 2)\n",
        "#   - target_role (the role they're applying for)\n",
        "#   - context (recruiter requirements from the tool)\n",
        "#\n",
        "# The prompt should:\n",
        "#   1. Persona: senior hiring manager at a FAANG company\n",
        "#   2. Find exactly 3 specific problems with the rewrite\n",
        "#   3. Produce the final, perfected bullet point\n",
        "#   4. Return JSON with: problems, final_version, confidence_score\n",
        "\n",
        "prompt_3 = f\"\"\"\n",
        "\n",
        "YOUR PROMPT HERE\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ===================== END YOUR CODE ========================\n",
        "\n",
        "# --- Don't modify below this line ---\n",
        "response_3 = model.generate_content(prompt_3)\n",
        "text_3 = response_3.text.strip()\n",
        "if text_3.startswith('```'):\n",
        "    text_3 = text_3.split('\\n', 1)[1]\n",
        "if text_3.endswith('```'):\n",
        "    text_3 = text_3.rsplit('```', 1)[0]\n",
        "\n",
        "result_3 = json.loads(text_3.strip())\n",
        "\n",
        "# Pretty display\n",
        "print(\"[THINKING] Self-Critique Results:\")\n",
        "print(\"\\nProblems found:\")\n",
        "for i, problem in enumerate(result_3['problems'], 1):\n",
        "    print(f\"  {i}. {problem}\")\n",
        "\n",
        "print(f\"\\n[OK] Final Version: {result_3['final_version']}\")\n",
        "print(f\"\\n[STATS] Confidence: {result_3['confidence_score']}/10\")\n",
        "\n",
        "# === THE BEFORE / AFTER ===\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"[NOTE] BEFORE vs AFTER\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[X] Before: \\\"{resume_bullet}\\\"\")\n",
        "print(f\"\\n[OK] After:  \\\"{result_3['final_version']}\\\"\")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What just happened?\n",
        "\n",
        "Your agent just **reviewed and corrected its own work**. This is the Reflection Pattern:\n",
        "\n",
        "```\n",
        "Output (Level 2) → Critique → Fix → Final Output\n",
        "```\n",
        "\n",
        "This is the exact same pattern used in:\n",
        "- **Google's Gemini** — internal review loops before responding\n",
        "- **Devin** (the AI SDE) — writes code, runs tests, fixes bugs\n",
        "- **AutoGPT** — plans, executes, evaluates, adjusts\n",
        "\n",
        "You just built it from scratch.\n",
        "\n",
        "**Agentic Pattern #3: Self-Correction** [CHECK]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Full Pipeline\n",
        "\n",
        "Let's wrap everything into one function so you can roast any bullet in a single call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def stage_print(stage, icon, color, message):\n",
        "    \"\"\"Print a visually distinct stage header.\"\"\"\n",
        "    colors = {\n",
        "        'cyan': '\\033[96m',\n",
        "        'red': '\\033[91m',\n",
        "        'green': '\\033[92m',\n",
        "        'yellow': '\\033[93m',\n",
        "        'magenta': '\\033[95m',\n",
        "        'white': '\\033[97m',\n",
        "        'reset': '\\033[0m'\n",
        "    }\n",
        "    c = colors.get(color, colors['white'])\n",
        "    r = colors['reset']\n",
        "    print(f\"\\n{c}{'='*60}{r}\")\n",
        "    try:\n",
        "        # Try printing with icon\n",
        "        print(f\"{c}{icon}  [ {stage} ]{r}\")\n",
        "    except UnicodeEncodeError:\n",
        "        # Fallback if terminal doesn't support emoji\n",
        "        print(f\"{c}[ {stage} ]{r}\")\n",
        "    print(f\"{c}{'='*60}{r}\")\n",
        "    time.sleep(0.5)\n",
        "    print(f\"\\n{message}\\n\")\n",
        "\n",
        "\n",
        "def thinking_dots(text, duration=1.5):\n",
        "    \"\"\"Simulate agent thinking.\"\"\"\n",
        "    import sys\n",
        "    sys.stdout.write(f\"\\033[90m{text}\")\n",
        "    for _ in range(3):\n",
        "        time.sleep(duration / 3)\n",
        "        sys.stdout.write(\".\")\n",
        "        sys.stdout.flush()\n",
        "    print(\"\\033[0m\")\n",
        "\n",
        "\n",
        "def get_role_requirements(role: str) -> str:\n",
        "    \"\"\"TOOL: Returns what recruiters look for in a specific role.\"\"\"\n",
        "    requirements = {\n",
        "        \"software engineer\": \"Strong DSA fundamentals, system design, clean code practices, CI/CD experience, testing frameworks, specific language/framework expertise (not just 'Python'), quantified impact metrics (%, $, users), open source contributions\",\n",
        "        \"data scientist\": \"Statistical modeling, Python/R proficiency, SQL mastery, ML frameworks (scikit-learn, PyTorch), A/B testing design, business impact quantification, data pipeline experience, visualization skills\",\n",
        "        \"product manager\": \"User research methodology, metrics-driven decisions (DAU, retention, conversion), roadmap planning, stakeholder management, market analysis, A/B testing, PRD writing\",\n",
        "        \"ml engineer\": \"Model training and fine-tuning, MLOps (MLflow, Kubeflow), distributed training, model serving (TensorRT, ONNX), data pipeline engineering, experiment tracking, production deployment\",\n",
        "        \"frontend developer\": \"React/Vue/Angular expertise, performance optimization (Core Web Vitals), accessibility (WCAG), responsive design, state management, testing (Jest, Cypress), design system experience\",\n",
        "        \"backend developer\": \"API design (REST/GraphQL), database optimization (SQL + NoSQL), caching strategies, message queues, microservices architecture, monitoring/observability, load testing\",\n",
        "        \"devops engineer\": \"CI/CD pipeline design, IaC (Terraform, Pulumi), container orchestration (K8s), monitoring (Prometheus, Grafana), cloud platforms (AWS/GCP/Azure), security best practices, incident response\"\n",
        "    }\n",
        "    role_lower = role.lower()\n",
        "    for key, value in requirements.items():\n",
        "        if key in role_lower:\n",
        "            return value\n",
        "    return \"Quantified achievements, specific technologies, measurable impact, action verbs, industry-specific keywords, problem-solving examples\"\n",
        "\n",
        "\n",
        "def call_llm(prompt, retries=4, delay=10):\n",
        "    \"\"\"Call Gemini and return parsed JSON with retry logic and rate-limit backoff.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            text = response.text.strip()\n",
        "            if text.startswith('```'):\n",
        "                text = text.split('\\n', 1)[1]\n",
        "            if text.endswith('```'):\n",
        "                text = text.rsplit('```', 1)[0]\n",
        "            return json.loads(text.strip())\n",
        "        except Exception as e:\n",
        "            err_str = str(e).lower()\n",
        "            is_rate_limit = \"429\" in str(e) or \"resource exhausted\" in err_str or \"quota\" in err_str\n",
        "            if is_rate_limit and attempt < retries - 1:\n",
        "                print(f\"\\n\\033[93mRate limit hit. Retrying in {delay}s... (attempt {attempt+1}/{retries})\\033[0m\")\n",
        "                time.sleep(delay)\n",
        "                delay = min(delay * 2, 65)  # Exponential backoff, cap at 65s\n",
        "            else:\n",
        "                if is_rate_limit:\n",
        "                    print(\"\\033[91mQuota exceeded. Use gemini-2.5-flash in Setup, or try again later.\\033[0m\")\n",
        "                raise e\n",
        "\n",
        "\n",
        "print(\"[OK] Helpers loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# BONUS LEVELS\n",
        "\n",
        "You've completed the core agent. Now let's add superpowers.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BONUS: ATS Score Gamification\n",
        "\n",
        "How well would your bullet survive an Applicant Tracking System? Let's find out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ATS SCORE — Before vs After\n",
        "# ============================================================\n",
        "\n",
        "original_bullet = resume_bullet\n",
        "final_bullet = result_3['final_version']  # From Level 3\n",
        "\n",
        "ats_prompt = f\"\"\"You are an Applicant Tracking System (ATS) scanner.\n",
        "Score these two resume bullets for ATS compatibility for a {target_role} role.\n",
        "\n",
        "Key factors: action verbs, quantified metrics, relevant keywords,\n",
        "specificity, industry standard terminology.\n",
        "\n",
        "Recruiters for {target_role} look for: {context}\n",
        "\n",
        "Bullet A (original): \"{original_bullet}\"\n",
        "Bullet B (improved): \"{final_bullet}\"\n",
        "\n",
        "Return ONLY valid JSON with:\n",
        "- \"original_ats_score\": integer 1-100\n",
        "- \"final_ats_score\": integer 1-100\n",
        "- \"improvement\": percentage improvement as a string (e.g., \"+65%\")\n",
        "- \"ats_tips\": list of 3 tips for even higher ATS compatibility\n",
        "\"\"\"\n",
        "\n",
        "response_ats = model.generate_content(ats_prompt)\n",
        "text_ats = response_ats.text.strip()\n",
        "if text_ats.startswith('```'):\n",
        "    text_ats = text_ats.split('\\n', 1)[1]\n",
        "if text_ats.endswith('```'):\n",
        "    text_ats = text_ats.rsplit('```', 1)[0]\n",
        "ats_result = json.loads(text_ats.strip())\n",
        "\n",
        "# Display\n",
        "print(\"[ROBOT] ATS COMPATIBILITY SCAN\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"\\n[X] Original: {ats_result['original_ats_score']}/100\")\n",
        "bar_orig = \"\\u2588\" * (ats_result['original_ats_score'] // 5) + \"\\u2591\" * (20 - ats_result['original_ats_score'] // 5)\n",
        "print(f\"   [{bar_orig}]\")\n",
        "\n",
        "print(f\"\\n[OK] Final:    {ats_result['final_ats_score']}/100\")\n",
        "bar_final = \"\\u2588\" * (ats_result['final_ats_score'] // 5) + \"\\u2591\" * (20 - ats_result['final_ats_score'] // 5)\n",
        "print(f\"   [{bar_final}]\")\n",
        "\n",
        "print(f\"\\n[CHART] Improvement: {ats_result['improvement']}\")\n",
        "print(f\"\\n[TIP] Tips for even higher scores:\")\n",
        "for tip in ats_result['ats_tips']:\n",
        "    print(f\"   \\u2022 {tip}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## SECRET LEVEL 4: Deploy as a Web App\n",
        "\n",
        "Right now, your agent lives in a notebook. Let's turn it into a **live web app** with a public URL — in 5 lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SECRET LEVEL 4: Deploy with Gradio\n",
        "# ============================================================\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def roast_app(bullet: str, role: str) -> str:\n",
        "    \"\"\"Wrapper for the Gradio interface.\"\"\"\n",
        "    try:\n",
        "        result = roast_my_resume(bullet, role)\n",
        "        output = f\"\"\"## Results\\n\n",
        "**Original:** \\\"{result['original']}\\\"\\n\n",
        "**Initial Score:** {result['initial_score']}/10\\n\n",
        "**Roast:** {result['roast']}\\n\n",
        "---\\n\n",
        "**Problems Found:**\\n\"\"\"\n",
        "        for i, p in enumerate(result['problems_found'], 1):\n",
        "            output += f\"{i}. {p}\\n\"\n",
        "        output += f\"\"\"\\n---\\n\n",
        "**Final Version:** \\\"{result['final_version']}\\\"\\n\n",
        "**Confidence:** {result['confidence']}/10\n",
        "\"\"\"\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}. Try again!\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=roast_app,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Resume Bullet\", placeholder=\"Paste your resume bullet here...\"),\n",
        "        gr.Dropdown(\n",
        "            label=\"Target Role\",\n",
        "            choices=[\"Software Engineer\", \"Data Scientist\", \"Product Manager\",\n",
        "                     \"ML Engineer\", \"Frontend Developer\", \"Backend Developer\",\n",
        "                     \"DevOps Engineer\"],\n",
        "            value=\"Software Engineer\"\n",
        "        ),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Agent Output\"),\n",
        "    title=\"[FIRE] Roast My Resume Agent\",\n",
        "    description=\"An AI agent that roasts your resume, rewrites it, and argues with itself to make it perfect.\",\n",
        "    examples=[\n",
        "        [\"Proficient in MS Office and team management\", \"Software Engineer\"],\n",
        "        [\"Familiar with machine learning concepts\", \"ML Engineer\"],\n",
        "        [\"Good communication skills\", \"Product Manager\"],\n",
        "    ],\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # share=True gives you a PUBLIC URL!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**You just deployed an AI application.** Copy the public URL and send it to anyone — they can use your agent from their phone.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BONUS: LinkedIn Post Generator\n",
        "\n",
        "You just built and deployed an AI agent. Let the world know."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LINKEDIN POST GENERATOR\n",
        "# ============================================================\n",
        "\n",
        "linkedin_prompt = \"\"\"You are a LinkedIn post writer for a college student who just\n",
        "built their first AI agent at a workshop.\n",
        "\n",
        "Write a professional but enthusiastic LinkedIn post (150-200 words) about:\n",
        "- They attended the \"Level Up to Agentic AI\" workshop by IEEE IGDTUW\n",
        "- Mentored by Ishan (AI Engineer, GDG Cloud New Delhi speaker)\n",
        "- They built a \"Roast My Resume\" AI Agent from scratch in Python\n",
        "- The agent uses 3 agentic patterns: Structured Output, Tool Calling, Self-Correction\n",
        "- They deployed it as a live web app using Gradio\n",
        "- They're excited about AI Engineering and Agentic AI\n",
        "\n",
        "Make it sound genuine, not salesy. Include 3-4 relevant hashtags.\n",
        "Don't use excessive emojis — keep it professional.\n",
        "\n",
        "Return ONLY valid JSON with:\n",
        "- \"post\": the full LinkedIn post text\n",
        "- \"hashtags\": list of hashtags used\n",
        "\"\"\"\n",
        "\n",
        "response_li = model.generate_content(linkedin_prompt)\n",
        "text_li = response_li.text.strip()\n",
        "if text_li.startswith('```'):\n",
        "    text_li = text_li.split('\\n', 1)[1]\n",
        "if text_li.endswith('```'):\n",
        "    text_li = text_li.rsplit('```', 1)[0]\n",
        "li_result = json.loads(text_li.strip())\n",
        "\n",
        "print(\"[NOTE] Your LinkedIn Post (copy-paste ready):\\n\")\n",
        "print(\"=\" * 50)\n",
        "print(li_result['post'])\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n[CLIP] Just copy the text above and paste it into LinkedIn!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## What You Built Today\n",
        "\n",
        "| Pattern | What It Does | Where It's Used in Production |\n",
        "|---------|-------------|------------------------------|\n",
        "| **Structured Output** | LLM returns JSON, not prose | Every AI agent ever |\n",
        "| **Tool Use** | Agent calls functions for external data | Google Search, API calls, DB queries |\n",
        "| **Self-Correction** | Agent critiques and fixes its own output | Devin, AutoGPT, production pipelines |\n",
        "\n",
        "### Where to Go Next\n",
        "\n",
        "- **LangGraph** — Build multi-agent systems with complex orchestration\n",
        "- **MCP (Model Context Protocol)** — Universal standard for agent tools\n",
        "- **Vertex AI / Cloud Run** — Deploy agents to production 24/7\n",
        "- **Google AI Studio** — Your API key is free forever. Keep building.\n",
        "\n",
        "### You just built what companies pay ₹20L+ for. Keep building.\n",
        "\n",
        "---\n",
        "\n",
        "*Workshop by Ishan — AI Engineer | GDG Cloud New Delhi*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
